#TODO: Check if structure makes sense (and not overkill!)
# 1) yaml experiments for upfront config and "one-click" running of e2e inference pipeline (incl. looping over multiple expYZ)
# 2) Class registry, config loader and experiment runner script for easy extensibility, adaptibility and modular config
# 3) data_models.py, base_classes.py, ingestion.py to pre-define main elements (e.g. "dirichlet prior" -> dirichlet_prior() as classmethod in defined classes)
# 4) Evaluation also with pre-defined metrics in yaml and classmethods (e.g. plot_autocorrelation())
# -> all main methods are pre-defined as classmethods and can be dynamically and modularly selected with yaml

experiments:
  bwh_metadata_path: "/path/to/metadata.json"
  bwh_signals_path: "/path/to/signals.csv"

  exp1:
    output_path: "results/exp1/"
    d_vector: "logspace(1e-4, 1e-1, 60)"
    b_vector: [0, 50, 250, 500, 1000, 1250]

    prob_model:
      prior:
        type: "dirichlet"
        alpha: 0.1
      inference:
        method: "gibbs"
        iterations: 5000
        burn_in: 500

    cancer_biomarker: "gleason"

    metrics:
      mutual_coherence: true
      sensitivity_map: true
      resolution_kernel: true
      autocorrelation_plot: true
